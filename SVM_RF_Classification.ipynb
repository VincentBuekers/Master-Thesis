{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest support vector machine classifier (RF-SVC)\n",
    "## Vincent Buekers\n",
    "Promotor: Prof. dr. Johan A.K. Suykens\n",
    "\n",
    "Supervision: Yingyi Chen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets, tree, svm, linear_model, preprocessing\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedShuffleSplit\n",
    "\n",
    "from statistics import mode, StatisticsError\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition input space into subsets \n",
    "Subsets are obtained from the leaf nodes of an extremely randomized tree. For purposes of theoretical consistency, only one candidate feature is selected from all d features using the option max_features = 1, yielding totally random trees.\n",
    "\n",
    "Note: these are non-overlapping subsets due to the recursive branching mechanism in decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_partition(X_train,X_test, y_train,y_test, idx_train,idx_test):\n",
    "\n",
    "    subsets = []\n",
    "    \n",
    "    # totally randomized tree (max_features=1)\n",
    "    extra = tree.ExtraTreeClassifier(max_features=1,min_samples_leaf = int(np.sqrt(len(X_train))) )\n",
    "    extra.fit(X_train,y_train)\n",
    "    \n",
    "    # obtain leaf indices the datapoints appear in\n",
    "    leaf_idx_train, leaf_idx_test = extra.apply(X_train), extra.apply(X_test)\n",
    "    \n",
    "    # Keep track of observation indexes and prepare for pandas' .groupby\n",
    "    leaf_idx_train = pd.DataFrame(leaf_idx_train, index=idx_train)\n",
    "    leaf_idx_test = pd.DataFrame(leaf_idx_test, index=idx_test)\n",
    "    \n",
    "    # Group train and test observations by their leaf node\n",
    "    groups_train = leaf_idx_train.groupby(leaf_idx_train[0],axis=0).groups\n",
    "    groups_test = leaf_idx_test.groupby(leaf_idx_test[0],axis=0).groups\n",
    "    \n",
    "    # collect all data back into one array, sorted by original observation indexes\n",
    "    X_train, X_test = np.c_[idx_train,X_train], np.c_[idx_test,X_test]\n",
    "    y_train, y_test = np.c_[idx_train,y_train], np.c_[idx_test,y_test]\n",
    "    X, y = np.r_[X_train,X_test], np.r_[y_train,y_test]\n",
    "    X, y = X[np.argsort(X[:,0])], y[np.argsort(y[:,0])]\n",
    "    X, y = np.delete(X, 0, 1), np.delete(y, 0, 1)\n",
    "    \n",
    "    # tree predictions (only test observations will be retrieved later on)\n",
    "    preds_tree = extra.predict(X).reshape(-1,1)\n",
    "    \n",
    "    # Obtain train and test subsets created by the leaf node partitioning\n",
    "    # iterables are a list of Int64index objects for the data in each leaf node\n",
    "    for leaf_train, leaf_test in zip(list(groups_train.values()),list(groups_test.values())) :\n",
    "        \n",
    "        # subset the data\n",
    "        X_train_sub, y_train_sub = X[leaf_train], y[leaf_train]\n",
    "        X_test_sub, y_test_sub, y_tree = X[leaf_test] ,y[leaf_test], preds_tree[leaf_test]\n",
    "        \n",
    "        # original indexes of the observations appearing in this leaf\n",
    "        train_indexes = np.array(leaf_train).reshape(-1,1)\n",
    "        test_indexes = np.array(leaf_test).reshape(-1,1)\n",
    "        \n",
    "        # training subset including original observation indexes\n",
    "        sub_train = np.concatenate((train_indexes, X_train_sub, y_train_sub), axis=1)\n",
    "        # testing subset including original observation indexes and tree predictions\n",
    "        sub_test = np.concatenate((test_indexes, X_test_sub, y_test_sub, y_tree), axis=1)\n",
    "\n",
    "        subsets.append([sub_train,sub_test])\n",
    "    \n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedded SVM classifiers\n",
    "for each subset an svm classifier is trained on the training subset and used to predict the corresponding leaf test test (if the leaf is not yet homogenous in terms of class labels). \n",
    "\n",
    "- fit_svc_linear: LinearSVC (LibLinear)\n",
    "- fit_svc_sgd: SGDClassifier \n",
    "- fit_svc_kernel: tuned kernel svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Svm fitting and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svc_linear(subset):\n",
    "    \n",
    "    idx_train, X_train, y_train = subset[0][:,0], subset[0][:,1:-1], subset[0][:,-1]\n",
    "    idx_test,X_test,y_test,y_tree = subset[1][:,0],subset[1][:,1:-2],subset[1][:,-2],subset[1][:,-1]\n",
    "        \n",
    "    # check if leaf node is heterogeneous (i.e. consists of more than one class) \n",
    "    # also check if it contains enough samples to conduct training (2)\n",
    "    if len(np.unique(y_train)) >= 2 and (np.bincount(y_train.astype(int)) >= 2).all():\n",
    "        \n",
    "        # decide whether to solve in primal or dual\n",
    "        QP_bool = False if (X_train.shape[0] > X_train.shape[0]) else True\n",
    "        \n",
    "        # fit svm to subset\n",
    "        clf = svm.LinearSVC(class_weight='balanced', dual=QP_bool)\n",
    "        clf.fit(X_train,y_train)\n",
    "        \n",
    "        # obtain predictions for subset\n",
    "        svm_pred = clf.predict(X_test)\n",
    "        svm_pred = np.concatenate((idx_test.reshape(-1,1), svm_pred.reshape(-1,1)), axis=1)\n",
    "        \n",
    "        return svm_pred\n",
    "    \n",
    "    # use tree predictions if leaf (subset) is already pure   \n",
    "    else:\n",
    "        tree_pred = np.concatenate((idx_test.reshape(-1,1), y_tree.reshape(-1,1)), axis=1)\n",
    "        \n",
    "        return tree_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svc_sgd(subset):\n",
    "    \n",
    "    idx_train, X_train, y_train = subset[0][:,0], subset[0][:,1:-1], subset[0][:,-1]\n",
    "    idx_test,X_test,y_test,y_tree = subset[1][:,0],subset[1][:,1:-2],subset[1][:,-2],subset[1][:,-1]\n",
    "        \n",
    "    # check if leaf node is heterogeneous (i.e. consists of more than one class)\n",
    "    if len(np.unique(y_train)) >= 2 and (np.bincount(y_train.astype(int)) >= 2).all():\n",
    "        \n",
    "        # fit svm to subset\n",
    "        clf = linear_model.SGDClassifier(class_weight='balanced', early_stopping=True)\n",
    "        clf.fit(X_train,y_train)\n",
    "        \n",
    "        # obtain predictions for subset\n",
    "        svm_pred = clf.predict(X_test)\n",
    "        svm_pred = np.concatenate((idx_test.reshape(-1,1), svm_pred.reshape(-1,1)), axis=1)\n",
    "        \n",
    "        return svm_pred\n",
    "    \n",
    "    # use tree predictions if leaf (subset) is already pure   \n",
    "    else:\n",
    "        tree_pred = np.concatenate((idx_test.reshape(-1,1), y_tree.reshape(-1,1)), axis=1)\n",
    "        \n",
    "        return tree_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svc_kernel(subset):\n",
    "    \n",
    "    idx_train, X_train, y_train = subset[0][:,0], subset[0][:,1:-1], subset[0][:,-1]\n",
    "    idx_test,X_test,y_test,y_tree = subset[1][:,0],subset[1][:,1:-2],subset[1][:,-2],subset[1][:,-1]\n",
    "    \n",
    "    C_range = np.logspace(-2, 10, 13)\n",
    "    gamma_range = np.logspace(-9, 3, 13)\n",
    "    kernel_list = ['linear','rbf','poly']\n",
    "    param_grid = dict(gamma=gamma_range, C=C_range, kernel=kernel_list)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    # check if leaf node is heterogeneous (i.e. consists of more than one class)\n",
    "    if len(np.unique(y_train)) >= 2 and (np.bincount(y_train.astype(int)) >= 2).all():\n",
    "\n",
    "        # fit svm to subset\n",
    "        cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2)\n",
    "        clf = svm.SVC(class_weight='balanced')\n",
    "        tuned = RandomizedSearchCV(clf, param_distributions=param_grid, cv=cv, n_jobs=-1)\n",
    "        tuned.fit(X_train, y_train)\n",
    "        \n",
    "        #print(tuning.best_params_)\n",
    "            \n",
    "        # obtain predictions for subset\n",
    "        svm_pred = tuned.predict(X_test)\n",
    "        svm_pred = np.concatenate((idx_test.reshape(-1,1), svm_pred.reshape(-1,1)), axis=1)\n",
    "        \n",
    "        return svm_pred\n",
    "    \n",
    "    # use tree predictions if leaf (subset) is already pure   \n",
    "    else:\n",
    "        tree_pred = np.concatenate((idx_test.reshape(-1,1), y_tree.reshape(-1,1)), axis=1)\n",
    "        \n",
    "        return tree_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concurrent execution of svms within tree\n",
    "Within each decision tree, the SVMs can be trained in parallel to achieve optimal computational efficiency.\n",
    "\n",
    "- svc_tree_linear: extratree with LinearSVC (LibLinear) in leaf node\n",
    "- svc_tree_sgd: extratree with SGDClassifier in leaf node\n",
    "- svc_tree_kernel: extratree with tuned kernel svm in leaf node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_tree_linear(X_train,X_test, y_train,y_test, idx_train,idx_test):\n",
    "    \n",
    "    # Obtain subsets through ExtraTree partitioning\n",
    "    subsets = extra_partition(X_train,X_test, y_train,y_test, idx_train,idx_test)\n",
    "    \n",
    "    #print(\"This Tree has been partitioned into {} leaf nodes\".format(len(subsets)))\n",
    "    \n",
    "    preds_leaf = []\n",
    "    \n",
    "    # Run SVM's in parallel\n",
    "    with Parallel() as parallel:\n",
    "        result = parallel(delayed(fit_svc_linear)(subset) for subset in subsets)\n",
    "        preds_leaf.append(result)\n",
    "        \n",
    "    # aggregate predictions of the leafs into one set of predictions for the tree\n",
    "    preds_all = np.concatenate(preds_leaf[0],axis=0)\n",
    "    \n",
    "    # sort predictions by their index\n",
    "    preds_sorted = preds_all[np.argsort(preds_all[:,0])]\n",
    "    \n",
    "    return preds_sorted[:,1].reshape(-1,1) # return predictions without index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_tree_sgd(X_train,X_test, y_train,y_test, idx_train,idx_test):\n",
    "    \n",
    "    # Obtain subsets through ExtraTree partitioning\n",
    "    subsets = extra_partition(X_train,X_test, y_train,y_test, idx_train,idx_test)\n",
    "        \n",
    "    preds_leaf = []\n",
    "    \n",
    "    # Run SVM's in parallel\n",
    "    with Parallel() as parallel:\n",
    "        result = parallel(delayed(fit_svc_sgd)(subset) for subset in subsets)\n",
    "        preds_leaf.append(result)\n",
    "        \n",
    "    # aggregate predictions of the leafs into one set of predictions for the tree\n",
    "    preds_all = np.concatenate(preds_leaf[0],axis=0)\n",
    "    \n",
    "    # sort predictions by their index\n",
    "    preds_sorted = preds_all[np.argsort(preds_all[:,0])]\n",
    "    \n",
    "    return preds_sorted[:,1].reshape(-1,1) # return predictions without index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_tree_kernel(X_train,X_test, y_train,y_test, idx_train,idx_test):\n",
    "    \n",
    "    # Obtain subsets through ExtraTree partitioning\n",
    "    subsets = extra_partition(X_train,X_test, y_train,y_test, idx_train,idx_test)\n",
    "        \n",
    "    preds_leaf = []\n",
    "    \n",
    "    # Run SVM's in parallel\n",
    "    with Parallel() as parallel:\n",
    "        result = parallel(delayed(fit_svc_kernel)(subset) for subset in subsets)\n",
    "        preds_leaf.append(result)\n",
    "        \n",
    "    # aggregate predictions of the leafs into one set of predictions for the tree\n",
    "    preds_all = np.concatenate(preds_leaf[0],axis=0)\n",
    "    \n",
    "    # sort predictions by their index\n",
    "    preds_sorted = preds_all[np.argsort(preds_all[:,0])]\n",
    "    \n",
    "    return preds_sorted[:,1].reshape(-1,1) # return predictions without index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def svm_tree(X,y, X_train,X_test, y_train,y_test, idx_train,idx_test):\n",
    "    \n",
    "    subsets = get_groups(X,y, X_train,X_test, y_train,y_test, idx_train,idx_test)\n",
    "    \n",
    "    preds_leaf = []\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for subset in subsets:\n",
    "        \n",
    "        # Train data stored in first element of each leaf (subset)\n",
    "        idx_train, X_train, y_train = subset[0][:,0], subset[0][:,1:-1], subset[0][:,-1]\n",
    "        # test data  stored in second element of each leaf (subset)\n",
    "        idx_test,X_test,y_test,y_tree = subset[1][:,0],subset[1][:,1:-2],subset[1][:,-2],subset[1][:,-1]\n",
    "        \n",
    "        # check if leaf node is heterogeneous (i.e. consists of more than one class)\n",
    "        if (len(np.unique(y_train)) >= 2):\n",
    "            \n",
    "            # svm classifier with Radial basis function kernel\n",
    "            clf = svm.SVC(kernel='rbf')\n",
    "            pipe = pipeline.Pipeline([('Scaler', preprocessing.StandardScaler()), ('svc', clf)])\n",
    "            # fit svm to subset\n",
    "            pipe.fit(X_train,y_train)\n",
    "            \n",
    "            # obtain predictions for subset\n",
    "            svm_pred = pipe.predict(X_test)\n",
    "            # keep track of observaton indexes\n",
    "            svm_pred = np.concatenate((idx_test.reshape(-1,1), svm_pred.reshape(-1,1)), axis=1)\n",
    "            preds_leaf.append(svm_pred)\n",
    "            \n",
    "            count += 1\n",
    "        \n",
    "        # use tree predictions if leaf (subset) is already pure   \n",
    "        else:\n",
    "            tree_pred = np.concatenate((idx_test.reshape(-1,1), y_tree.reshape(-1,1)), axis=1)\n",
    "            preds_leaf.append(tree_pred)\n",
    "    \n",
    "    print(\"The input space has been partitioned into {} leaf nodes, i.e. samples.\".format(len(subsets)))\n",
    "\n",
    "    print(\"{} of which have been used for training an SVM\"\\\n",
    "          \" given the heterogeneity of those nodes.\".format(count))\n",
    "    print(\"The remaining {} samples have the inherited\"\\\n",
    "          \" prediction from the randomized tree.\".format(len(subsets)-count))\n",
    "    \n",
    "    # aggregate leaf predictions for all test samples across different nodes\n",
    "    preds_all = np.concatenate(preds_leaf,axis=0)\n",
    "    # sort predictions by their index\n",
    "    preds_sorted = preds_all[np.argsort(preds_all[:,0])]\n",
    "    \n",
    "    return preds_sorted[:,1].reshape(-1,1) # return predictions without index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Vote\n",
    "For classification, a majority vote is implemented to ultimately obtain the forest prediction, as is commonmy done in ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain majority vote for each datapoint\n",
    "def majority_vote(l):\n",
    "    try:\n",
    "        return mode(l)\n",
    "    except StatisticsError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM embedded Forest\n",
    "Finally, the above procedure can be extended to an ensemble of randomized trees with embedded SVMs. Apart from the parallel execution of the embedded svm predictors, the forest ensemble itself can also be concurrently executed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Run trees in parallel using all cores\n",
    "def rf_svc(X,y):\n",
    "\n",
    "    forest_pred=[]\n",
    "    \n",
    "    X_train,X_test, y_train,y_test, idx_train,idx_test = train_test_split(X,y\n",
    "                                                                          ,np.arange(len(X))\n",
    "                                                                       ,test_size=1/3, stratify=y)\n",
    "    \n",
    "    # Rescale input space to [0,1] range (for purposes of consistency)\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    # Run trees in parallel\n",
    "    with Parallel() as parallel:\n",
    "        forest_pred = parallel(delayed(svm_parallel)(X,y \n",
    "                                                     ,X_train,X_test \n",
    "                                                     ,y_train,y_test\n",
    "                                                     ,idx_train,idx_test) for i in range(1,trees))\n",
    "        \n",
    "    # training time\n",
    "    training_time = time.time() - t\n",
    "    \n",
    "    # reshape array such that column k denotes prediction for tree k\n",
    "    forest_pred = np.concatenate(forest_pred,axis=1)\n",
    "    # majority vote\n",
    "    majority = np.apply_along_axis(majority_vote, 1, forest_pred) \n",
    "    # order test set on index\n",
    "    test = y_test[np.argsort(idx_test)]\n",
    "    \n",
    "    # accuracy\n",
    "    accuracy = metrics.accuracy_score(test, majority)\n",
    "    \n",
    "    return accuracy, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
