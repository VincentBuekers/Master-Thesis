{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest support vector machine regressor (RF-SVR)\n",
    "## Vincent Buekers\n",
    "Promotor: Prof. dr. Johan A.K. Suykens\n",
    "\n",
    "Supervision: Yingyi Chen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import ensemble, svm, linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit, train_test_split\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTree Partition\n",
    "leafs are obtained from the leaf nodes of an extremely randomized tree. For purposes of theoretical consistency: \n",
    "\n",
    "- only one candidate feature is selected from all d features using the option max_features = 1, yielding totally random trees\n",
    "- the leaf size is set to sqrt(n)\n",
    "\n",
    "Note: these are non-overlapping leafs due to the recursive branching mechanism in decision trees\n",
    "Note2: store extratree predictions to use when leaf node are pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_partition(X_train, X_test, y_train, n_estimators=10):\n",
    "    \n",
    "    # totally randomized forest (max_features=1)\n",
    "    extra = ensemble.ExtraTreesRegressor(n_estimators=n_estimators,\n",
    "                                          max_features=1, \n",
    "                                          min_samples_leaf = int(np.sqrt(len(X_train))), \n",
    "                                          n_jobs=-1, \n",
    "                                          )\n",
    "    \n",
    "    extra.fit(X_train,y_train)\n",
    "\n",
    "    leaf_idx_train = pd.DataFrame(extra.apply(X_train))\n",
    "    leaf_idx_test = pd.DataFrame(extra.apply(X_test))\n",
    "\n",
    "    partitions={}\n",
    "    \n",
    "    for k in leaf_idx_train.columns:\n",
    "    \n",
    "        leafs_train = leaf_idx_train.groupby(leaf_idx_train[k],axis=0).groups\n",
    "        leafs_test = leaf_idx_test.groupby(leaf_idx_test[k],axis=0).groups\n",
    "\n",
    "        partition={}\n",
    "        \n",
    "        i=0\n",
    "    \n",
    "        for leaf_train, leaf_test in zip(leafs_train.values(), leafs_test.values()):\n",
    "        \n",
    "            X_train_sub, y_train_sub = X_train[leaf_train], y_train[leaf_train]\n",
    "            X_test_sub = X_test[leaf_test]\n",
    "    \n",
    "            leaf={}\n",
    "        \n",
    "            leaf.update({'X_train':X_train_sub,\n",
    "                         'y_train':y_train_sub, \n",
    "                         'X_test':X_test_sub, \n",
    "                         'index_test': leaf_test})\n",
    "        \n",
    "            partition.update({\"leaf_\"+str(i):leaf})\n",
    "            i+=1\n",
    "        \n",
    "        partitions.update({\"tree_\"+str(k):partition})\n",
    "        \n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded SVM regressors\n",
    "for each leaf of each tree, an svm classifier is trained on that training subset, subsequently used to predict the corresponding leaf test test\n",
    "\n",
    "- fit_svr_linear: LinearSVR (LibLinear)\n",
    "- fit_svr_sgd: SGDRegressor\n",
    "\n",
    "Whether the regressors should be tuned or not can be specified by setting tune = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svr_linear(leaf, tune):\n",
    "    \n",
    "    X_train, y_train = leaf[\"X_train\"], leaf[\"y_train\"]\n",
    "\n",
    "    if tune == True:\n",
    "            \n",
    "        # regularization values\n",
    "        C_range = np.logspace(-1,1,6)\n",
    "        grid = dict(C=C_range)\n",
    "        \n",
    "        # fit svm to leaf\n",
    "        cv = ShuffleSplit(n_splits=5, test_size=0.2)\n",
    "        reg = svm.LinearSVR(loss='squared_epsilon_insensitive',dual=False)\n",
    "        tuned = GridSearchCV(reg, param_grid= grid, cv=cv, n_jobs=-1)\n",
    "        tuned.fit(X_train,y_train)\n",
    "\n",
    "        return tuned\n",
    "        \n",
    "    else:\n",
    "            \n",
    "        reg = svm.LinearSVR(loss='squared_epsilon_insensitive', dual=False)\n",
    "        reg.fit(X_train,y_train)\n",
    "            \n",
    "        return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svr_sgd(leaf, tune):\n",
    "    \n",
    "    X_train, y_train = leaf[\"X_train\"], leaf[\"y_train\"]\n",
    "    n = X_train.shape[0]\n",
    "\n",
    "    if tune == True:\n",
    "            \n",
    "        alpha_range=10.0**-np.arange(1,7)\n",
    "        grid = dict(alpha=alpha_range)\n",
    "            \n",
    "        cv = ShuffleSplit(n_splits=5, test_size=0.2)\n",
    "        reg = linear_model.SGDRegressor(loss= \"epsilon_insensitive\", early_stopping=False, max_iter = np.ceil(10**6 / n))\n",
    "            \n",
    "        tuned = GridSearchCV(reg, param_grid=grid, cv=cv, n_jobs=-1)\n",
    "        tuned.fit(X_train,y_train)\n",
    "\n",
    "        return tuned\n",
    "        \n",
    "    else:\n",
    "        reg = linear_model.SGDRegressor(loss= \"epsilon_insensitive\", early_stopping=True,  max_iter = np.ceil(10**6 / n))\n",
    "        reg.fit(X_train,y_train)\n",
    "\n",
    "        return reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel training across nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svr_tree(leafs, variant, tune):\n",
    "    \n",
    "    # amount of leafs or leaf nodes\n",
    "    leaf_count = leafs.keys()\n",
    "    \n",
    "    if variant == \"linear\":\n",
    "        \n",
    "        # Run SVM's in parallel\n",
    "        with Parallel() as parallel:\n",
    "            leaf_models = parallel(delayed(fit_svr_linear)(leaf, tune) for leaf in leafs.values())\n",
    "    \n",
    "        leaf_models = dict(zip(leaf_count,leaf_models))\n",
    "        \n",
    "        return leaf_models\n",
    "    \n",
    "    elif variant == \"sgd\":\n",
    "        \n",
    "        # Run SVM's in parallel\n",
    "        with Parallel() as parallel:\n",
    "            leaf_models = parallel(delayed(fit_svr_sgd)(leaf, tune) for leaf in leafs.values())\n",
    "    \n",
    "        leaf_models = dict(zip(leaf_count,leaf_models))\n",
    "        \n",
    "        return leaf_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel training across trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rf_svr(partitions, variant, tune):\n",
    "    \n",
    "    tree_count = partitions.keys()\n",
    "    \n",
    "    with Parallel() as parallel:\n",
    "        forest = parallel(delayed(fit_svr_tree)(partition,variant, tune) for partition in partitions.values())\n",
    "        \n",
    "    forest = dict(zip(tree_count, forest))\n",
    "        \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_leaf(leaf, leaf_model):  \n",
    "    \n",
    "    idx_test, X_test= leaf[\"index_test\"], leaf[\"X_test\"]\n",
    "  \n",
    "    # obtain predictions for leaf\n",
    "    pred = leaf_model.predict(X_test)\n",
    "    # include original observation index\n",
    "    pred = dict(zip(idx_test, pred))\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tree(leafs,leaf_models):\n",
    "    \n",
    "    # Predict SVM's in parallel\n",
    "    with Parallel() as parallel:\n",
    "        preds = parallel(delayed(predict_leaf)(leaf, leaf_model) for leaf,leaf_model in zip(leafs.values(),leaf_models.values()))\n",
    "    \n",
    "    preds_all = {}\n",
    "    for leaf_preds in preds:\n",
    "        preds_all.update(leaf_preds)\n",
    "        \n",
    "    preds_sorted=[]\n",
    "    for key in sorted(preds_all):\n",
    "        preds_sorted.append(preds_all[key])\n",
    "    \n",
    "    return np.array(preds_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_forest(partitions,forest):\n",
    "    \n",
    "    forest_pred = []\n",
    "    \n",
    "    for leafs, leaf_models in zip(partitions.values(),forest.values()):\n",
    "        \n",
    "        tree_pred = predict_tree(leafs, leaf_models)\n",
    "        tree_pred = tree_pred.reshape(-1,1)\n",
    "        forest_pred.append(tree_pred)\n",
    "        \n",
    "    # reshape array such that column k denotes prediction for tree k\n",
    "    forest_pred = np.concatenate(forest_pred,axis=1)\n",
    "    # mean predicition\n",
    "    mean_pred = np.apply_along_axis(np.mean, 1, forest_pred) \n",
    "   \n",
    "    return mean_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
