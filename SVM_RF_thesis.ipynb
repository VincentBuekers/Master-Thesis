{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Embedded Forests\n",
    "### Vincent Buekers\n",
    "### Master of statistics thesis, KUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets, ensemble, tree, svm, model_selection, metrics\n",
    "\n",
    "import multiprocessing as multip\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X=datasets.load_iris(return_X_y=True)[0]\n",
    "y=datasets.load_iris(return_X_y=True)[1].reshape(-1,1)\n",
    "\n",
    "# amount of trees in forest\n",
    "trees = 100\n",
    "# use all cores for multiprocessing later on\n",
    "nr_cores = multip.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition input space into subsets obtained from the leaf nodes of an extremely randomized tree\n",
    "Note: these are non-overlapping subsets due to the recursive branching mechanism used in such trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groups(X,y):\n",
    "    \n",
    "    subsets = []\n",
    "    \n",
    "    # extremely randomized tree\n",
    "    extra = tree.ExtraTreeClassifier(min_samples_leaf=1/10)\n",
    "    extra.fit(X,y)\n",
    "    # predictions\n",
    "    preds_tree = extra.predict(X).reshape(-1,1)\n",
    "    \n",
    "    # obtain leaf indices datapoints appear in\n",
    "    leaf_indexes = extra.apply(X)\n",
    "    leaf_indexes = pd.DataFrame(leaf_indexes)\n",
    "    \n",
    "    # Group observations by their leaf node\n",
    "    groups = leaf_indexes.groupby(leaf_indexes[0],axis=0).groups\n",
    "    \n",
    "    print(\"The input space has been partitioned into {} leaf nodes, i.e. samples.\".format(len(groups)))\n",
    "    \n",
    "    # Obtain subsets created by the leaf node partitioning\n",
    "    for value in list(groups.values()):\n",
    "        \n",
    "        X_sub, y_sub, y_tree = X[value],y[value], preds_tree[value].reshape(-1,1)\n",
    "        \n",
    "        group_indexes = np.array(value).reshape(-1,1)\n",
    "        \n",
    "        sub = np.concatenate((group_indexes, X_sub, y_sub, y_tree), axis=1)\n",
    "        subsets.append(sub)\n",
    "        \n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedded SVM classifiers\n",
    "for each subset an svm classifier is trained, given the subset consist of sufficient class labels. Otherwise, the predictions from the randomized tree are inherited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_tree(X,y):\n",
    "    \n",
    "    subsets = get_groups(X,y)\n",
    "    \n",
    "    # svm classifier\n",
    "    clf = svm.SVC()\n",
    "    \n",
    "    preds_leaf = []\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for subset in subsets:\n",
    "        \n",
    "        indexes, X, y, y_tree = subset[:,0], subset[:,1:-2], subset[:,-2] , subset[:,-1]\n",
    "        \n",
    "        # check if leaf node has sufficient class labels\n",
    "        if (len(np.unique(y)) >= 2):\n",
    "            # fit svm to subset\n",
    "            clf.fit(X,y)\n",
    "            # obtain predictions for subset\n",
    "            svm_pred = clf.predict(X)\n",
    "            svm_pred = np.concatenate((indexes.reshape(-1,1), svm_pred.reshape(-1,1)), axis=1)\n",
    "            \n",
    "            preds_leaf.append(svm_pred)\n",
    "            count += 1\n",
    "        \n",
    "        # use tree predictions if leaf (subset) is already pure   \n",
    "        else:\n",
    "            tree_pred = np.concatenate((indexes.reshape(-1,1), y_tree.reshape(-1,1)), axis=1)\n",
    "            preds_leaf.append(tree_pred)\n",
    "            \n",
    "    print(\"{} of which have been used for training an SVM\"\\\n",
    "          \" based on sufficient class labels.\".format(count))\n",
    "    print(\"The remaining {} samples have the inherited\"\\\n",
    "          \" prediction from the randomized tree.\".format(len(subsets)-count))\n",
    "    # combine leaf predictions of all the arrays\n",
    "    preds_all = np.concatenate(preds_leaf,axis=0)\n",
    "    return preds_all[np.argsort(preds_all[:,0])] # sort predictions by their index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the above procedure for multiple trees in parallel\n",
    "This results in a support vector machine embedded random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run trees in parallel using all cores\n",
    "def svm_forest(X,y):\n",
    "    forest = Parallel(nr_cores)(delayed(svm_tree)(X,y) for i in range(1,trees))\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = svm_forest(X,y)\n",
    "\n",
    "# reshape numpy array such that column k denotes prediction for tree k\n",
    "forest_pred = np.concatenate(forest_pred,axis=1)\n",
    "# remove excessive index columns\n",
    "forest_pred = np.delete(forest_pred, list(range(2, forest_pred.shape[1], 2)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode, StatisticsError\n",
    "\n",
    "majority = []\n",
    "\n",
    "# Obtain majority vote for each datapoint\n",
    "def majority_vote(l):\n",
    "    try:\n",
    "        return mode(l)\n",
    "    except StatisticsError:\n",
    "        return 0\n",
    "    \n",
    "for i in range(0, forest_pred.shape[0]):\n",
    "    majority.append(majority_vote(forest_pred[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# compute accuracy of svm forest\n",
    "metrics.accuracy_score(majority,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
