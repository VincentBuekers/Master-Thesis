{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSVT Classifier\n",
    "## - Vincent Buekers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import ensemble, svm, linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit, train_test_split\n",
    "\n",
    "from statistics import mode, StatisticsError\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTree Partition\n",
    "\n",
    "- only one candidate feature is selected from all d features using the option max_features = 1, yielding totally random trees\n",
    "- the leaf size is set proportional to sqrt(n)\n",
    "- the trees are trained in parallel for computational efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_partition(X_train, X_test, y_train, n_estimators=10, random_state=None, min_samples_factor=1):\n",
    "    \n",
    "    min_samples = int(min_samples_factor*np.sqrt(X_train.shape[0]))\n",
    "    \n",
    "    extra = ensemble.ExtraTreesClassifier(n_estimators=n_estimators,\n",
    "                                          max_features=1, \n",
    "                                          min_samples_leaf = min_samples, \n",
    "                                          n_jobs=-1, \n",
    "                                          random_state=random_state\n",
    "                                          )\n",
    "    \n",
    "    extra.fit(X_train,y_train)\n",
    "    y_pred_extra = extra.predict(X_test)\n",
    "\n",
    "    leaf_idx_train = pd.DataFrame(extra.apply(X_train))\n",
    "    leaf_idx_test = pd.DataFrame(extra.apply(X_test))\n",
    "\n",
    "    partitions={}\n",
    "    \n",
    "    for k in leaf_idx_train.columns:\n",
    "    \n",
    "        leafs_train = leaf_idx_train.groupby(leaf_idx_train[k],axis=0).groups\n",
    "        leafs_test = leaf_idx_test.groupby(leaf_idx_test[k],axis=0).groups\n",
    "\n",
    "        partition={}\n",
    "        \n",
    "        i=0\n",
    "    \n",
    "        for leaf_train, leaf_test in zip(leafs_train.values(), leafs_test.values()):\n",
    "        \n",
    "            X_train_sub, y_train_sub = X_train[leaf_train], y_train[leaf_train]\n",
    "            X_test_sub = X_test[leaf_test]\n",
    "            y_pred_sub = y_pred_extra[leaf_test]\n",
    "    \n",
    "            leaf={}\n",
    "        \n",
    "            leaf.update({'X_train':X_train_sub,\n",
    "                         'y_train':y_train_sub, \n",
    "                         'X_test':X_test_sub, \n",
    "                         'index_test': leaf_test,\n",
    "                         'y_pred_extra':y_pred_sub})\n",
    "        \n",
    "            partition.update({\"leaf_\"+str(i):leaf})\n",
    "            i+=1\n",
    "        \n",
    "        partitions.update({\"tree_\"+str(k):partition})\n",
    "        \n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM training\n",
    "- for each leaf, or local region, an svm classifier is trained on the training data stored in that leaf. \n",
    "- Each SVC is tuned specific to its own local region.\n",
    "- Note that it is not possible to train a leaf node that is already pure, in which case the prediction of the extremely randomized forest is adopted instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svc(leaf):\n",
    "    \n",
    "    X_train, y_train = leaf[\"X_train\"], leaf[\"y_train\"]\n",
    "    \n",
    "    # check if leaf node is heterogeneous (i.e. consists of more than one class) \n",
    "    # also check if it contains enough samples to conduct training (2)\n",
    "    if len(np.unique(y_train)) >= 2 and (pd.Series(y_train).value_counts() >= 2).all(): #(np.bincount(y_train.astype(int)) >= 2).all()\n",
    "        \n",
    "        # decide whether to solve in primal or dual\n",
    "        QP_bool = False if (X_train.shape[0] > X_train.shape[1]) else True\n",
    "            \n",
    "        # regularization values\n",
    "        C_range = np.logspace(-2,2,5,base=2)\n",
    "        grid = dict(C=C_range)\n",
    "        \n",
    "        # train svm on leaf data + optimize C by means of stratified CV \n",
    "        cv = StratifiedShuffleSplit(n_splits=3, test_size=1/3)\n",
    "        clf = svm.LinearSVC(class_weight='balanced', dual=QP_bool)#, random_state=random_fix)\n",
    "        tuned = GridSearchCV(clf, param_grid= grid, cv=cv, n_jobs=-1)\n",
    "        tuned.fit(X_train, y_train)\n",
    "\n",
    "        return tuned.best_estimator_\n",
    "\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel training across nodes and trees\n",
    "- the individual leaf SVMs are trained in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svc_tree(leafs):\n",
    "    \n",
    "    # amount of leafs or leaf nodes\n",
    "    leaf_count = leafs.keys()\n",
    "    \n",
    "    # Run SVM's in parallel\n",
    "    with Parallel() as parallel:\n",
    "        leaf_models = parallel(delayed(fit_svc)(leaf) for leaf in leafs.values())\n",
    "    \n",
    "    leaf_models = dict(zip(leaf_count,leaf_models))\n",
    "        \n",
    "    return leaf_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rsvt(partitions):\n",
    "    \n",
    "    tree_count = partitions.keys()\n",
    "    \n",
    "    with Parallel() as parallel:\n",
    "        forest = parallel(delayed(fit_svc_tree)(partition) for partition in partitions.values())\n",
    "        \n",
    "    forest = dict(zip(tree_count, forest))\n",
    "        \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "- The test subset stored within each leaf is predicted using its corresponding leaf model. \n",
    "- In the case a leaf node was already pure, i.e. consists of only one class, the prediction of the extra forest is used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_leaf(leaf, leaf_model):  \n",
    "    \n",
    "    idx_test, X_test, y_pred_extra = leaf[\"index_test\"], leaf[\"X_test\"], leaf[\"y_pred_extra\"], \n",
    "    \n",
    "    # use tree predictions if leaf node is pure\n",
    "    if leaf_model == None:\n",
    "        pred = dict(zip(idx_test,y_pred_extra))\n",
    "        return pred\n",
    "    \n",
    "    else:    \n",
    "        # obtain predictions for leaf\n",
    "        pred = leaf_model.predict(X_test)\n",
    "        # include original observation index\n",
    "        pred = dict(zip(idx_test, pred))\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tree(leafs,leaf_models):\n",
    "    \n",
    "    # Predict SVM's in parallel\n",
    "    with Parallel() as parallel:\n",
    "        preds = parallel(delayed(predict_leaf)(leaf, leaf_model) for leaf,leaf_model in zip(leafs.values(),leaf_models.values()))\n",
    "    \n",
    "    preds_all = {}\n",
    "    for leaf_preds in preds:\n",
    "        preds_all.update(leaf_preds)\n",
    "        \n",
    "    preds_sorted=[]\n",
    "    for key in sorted(preds_all):\n",
    "        preds_sorted.append(preds_all[key])\n",
    "    \n",
    "    return np.array(preds_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest prediction\n",
    "- forest predictions are obtained by aggregating the tree predicitions by means of a majority vote, as is commonly implemented in tree ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain majority vote for each datapoint\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "def majority_vote(l):\n",
    "    try:\n",
    "        return mode(l)\n",
    "    except StatisticsError:\n",
    "        return most_common(list(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_forest(partitions,forest):\n",
    "    \n",
    "    forest_pred = []\n",
    "    \n",
    "    for leafs, leaf_models in zip(partitions.values(),forest.values()):\n",
    "        \n",
    "        tree_pred = predict_tree(leafs, leaf_models)\n",
    "        tree_pred = tree_pred.reshape(-1,1)\n",
    "        forest_pred.append(tree_pred)\n",
    "        \n",
    "    # reshape array such that column k denotes prediction for tree k\n",
    "    forest_pred = np.concatenate(forest_pred,axis=1)\n",
    "    # majority vote\n",
    "    majority = np.apply_along_axis(majority_vote, 1, forest_pred) \n",
    "   \n",
    "    return majority"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
