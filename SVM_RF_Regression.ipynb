{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Embedded Forests\n",
    "### Vincent Buekers\n",
    "### Master of statistics thesis, KUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets, ensemble, tree, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import multiprocessing as multip\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X, y = datasets.load_boston(return_X_y=True)\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "# amount of trees in forest\n",
    "trees = 100\n",
    "# min samples in leaf\n",
    "min_leaf_size = int(np.sqrt(len(X)))\n",
    "\n",
    "# use all cores for multiprocessing later on\n",
    "nr_cores = multip.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition input space into subsets obtained from the leaf nodes of an extremely randomized tree\n",
    "Note: these are non-overlapping subsets due to the recursive branching mechanism used in such trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groups(X,y, X_train,X_test, y_train,y_test, idx_train,idx_test):\n",
    "    \n",
    "    subsets = []\n",
    "        \n",
    "    # totally randomized tree (max_features=1)\n",
    "    extra = tree.ExtraTreeRegressor(max_features=1, min_samples_leaf = int(np.sqrt(len(X))) )\n",
    "    extra.fit(X_train,y_train)\n",
    "    \n",
    "    # obtain leaf indices the datapoints appear in\n",
    "    leaf_idx_train, leaf_idx_test = extra.apply(X_train), extra.apply(X_test)\n",
    "    \n",
    "    # Keep track of observation indexes and prepare for pandas' .groupby\n",
    "    leaf_idx_train = pd.DataFrame(leaf_idx_train, index=idx_train)\n",
    "    leaf_idx_test = pd.DataFrame(leaf_idx_test, index=idx_test)\n",
    "    \n",
    "    # Group train and test observations by their leaf node\n",
    "    groups_train = leaf_idx_train.groupby(leaf_idx_train[0],axis=0).groups\n",
    "    groups_test = leaf_idx_test.groupby(leaf_idx_test[0],axis=0).groups\n",
    "        \n",
    "    # Obtain train and test subsets created by the leaf node partitioning\n",
    "    # iterables are a list of Int64index objects for the data in each leaf node\n",
    "    for value_train, value_test in zip(list(groups_train.values()),list(groups_test.values())) :\n",
    "        \n",
    "        # subset the data\n",
    "        X_train_sub, y_train_sub = X[value_train], y[value_train]\n",
    "        X_test_sub, y_test_sub = X[value_test] ,y[value_test]\n",
    "        \n",
    "        # original indexes of the observations appearing in this leaf\n",
    "        train_indexes = np.array(value_train).reshape(-1,1)\n",
    "        test_indexes = np.array(value_test).reshape(-1,1)\n",
    "        \n",
    "        # training subset including original observation indexes\n",
    "        sub_train = np.concatenate((train_indexes, X_train_sub, y_train_sub), axis=1)\n",
    "        # testing subset including original observation indexes and tree predictions\n",
    "        sub_test = np.concatenate((test_indexes, X_test_sub, y_test_sub), axis=1)\n",
    "\n",
    "        subsets.append([sub_train,sub_test])\n",
    "    \n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedded SVM Regressor\n",
    "for each subset an svm classifier is trained on the training subset and used to predict the corresponding leaf test test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialized Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_tree(X,y, X_train,X_test, y_train,y_test, idx_train,idx_test):\n",
    "    \n",
    "    subsets = get_groups(X,y, X_train,X_test, y_train,y_test, idx_train,idx_test)\n",
    "    \n",
    "    preds_leaf = []\n",
    "    \n",
    "    for subset in subsets:\n",
    "        \n",
    "        # Train data stored in first element of each leaf (subset)\n",
    "        idx_train, X_train, y_train = subset[0][:,0], subset[0][:,1:-1], subset[0][:,-1]\n",
    "        # test data  stored in second element of each leaf (subset)\n",
    "        idx_test, X_test, y_test = subset[1][:,0], subset[1][:,1:-1], subset[1][:,-1]\n",
    "        \n",
    "        # svm classifier with Radial basis function kernel\n",
    "        reg = svm.SVR(kernel='rbf')\n",
    "        # fit svm to subset\n",
    "        reg.fit(X_train,y_train)\n",
    "            \n",
    "        # obtain predictions for subset\n",
    "        svm_pred = reg.predict(X_test)\n",
    "        # keep track of observaton indexes\n",
    "        svm_pred = np.concatenate((idx_test.reshape(-1,1), svm_pred.reshape(-1,1)), axis=1)\n",
    "        preds_leaf.append(svm_pred)\n",
    "\n",
    "    # aggregate leaf predictions for all test samples across different nodes\n",
    "    preds_all = np.concatenate(preds_leaf,axis=0)\n",
    "    # sort predictions by their index\n",
    "    preds_sorted = preds_all[np.argsort(preds_all[:,0])]\n",
    "    return preds_sorted[:,1].reshape(-1,1) # return predictions without index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the above procedure for multiple trees in parallel\n",
    "This results in a support vector machine embedded random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run trees in parallel using all cores\n",
    "def svm_forest(X,y):\n",
    "   \n",
    "    X_train,X_test, y_train,y_test, idx_train,idx_test = train_test_split(X,y\n",
    "                                                                          ,np.arange(len(X))\n",
    "                                                                          ,test_size=1/3)\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    forest_pred = Parallel(nr_cores)(delayed(svm_tree)(X,y,X_train,X_test\n",
    "                                                  , y_train,y_test\n",
    "                                                  , idx_train,idx_test) for i in range(1,100))\n",
    "    \n",
    "    # training time\n",
    "    training_time = time.time() - t\n",
    "    \n",
    "    # reshape array such that column k denotes prediction for tree k\n",
    "    forest_pred = np.concatenate(forest_pred,axis=1)\n",
    "    \n",
    "    mean_pred = np.apply_along_axis(np.mean, 1, forest_pred) \n",
    "    \n",
    "    test = y_test[np.argsort(idx_test)]\n",
    "    \n",
    "    R_2 = metrics.r2_score(test, mean_pred)\n",
    "    \n",
    "    return R_2, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_2: 0.2739225850395439\n",
      "training time: 0.51 seconds\n"
     ]
    }
   ],
   "source": [
    "# Forest predictions and training time\n",
    "svm_rf = svm_forest(X,y)\n",
    "print(\"R_2: {}\".format(svm_rf[0]))\n",
    "print(\"training time: {0:.2f} seconds\".format(svm_rf[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
