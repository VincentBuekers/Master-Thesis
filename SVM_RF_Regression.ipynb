{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest support vector regressor (RF-SVR)\n",
    "## Vincent Buekers\n",
    "Promotor: Prof. dr. Johan A.K. Suykens\n",
    "\n",
    "Supervision: Yingyi Chen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition input space into subsets \n",
    "Subsets are obtained from the leaf nodes of an extremely randomized tree. For purposes of theoretical consistency, only one candidate feature is selected from all d features using the option max_features = 1, yielding totally random trees.\n",
    "\n",
    "Note: these are non-overlapping subsets due to the recursive branching mechanism in decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_partition(X_train,X_test, y_train,y_test, idx_train,idx_test):\n",
    "\n",
    "    subsets = []\n",
    "    \n",
    "    # totally randomized tree (max_features=1)\n",
    "    extra = tree.ExtraTreeRegressor(max_features=1,min_samples_leaf = int(np.sqrt(len(X_train))) )\n",
    "    extra.fit(X_train,y_train)\n",
    "    \n",
    "    # obtain leaf indices the datapoints appear in\n",
    "    leaf_idx_train, leaf_idx_test = extra.apply(X_train), extra.apply(X_test)\n",
    "    \n",
    "    # Keep track of observation indexes and prepare for pandas' .groupby\n",
    "    leaf_idx_train = pd.DataFrame(leaf_idx_train, index=idx_train)\n",
    "    leaf_idx_test = pd.DataFrame(leaf_idx_test, index=idx_test)\n",
    "    \n",
    "    # Group train and test observations by their leaf node\n",
    "    groups_train = leaf_idx_train.groupby(leaf_idx_train[0],axis=0).groups\n",
    "    groups_test = leaf_idx_test.groupby(leaf_idx_test[0],axis=0).groups\n",
    "    \n",
    "    # collect all data back into one array, sorted by original observation indexes\n",
    "    X_train, X_test = np.c_[idx_train,X_train], np.c_[idx_test,X_test]\n",
    "    y_train, y_test = np.c_[idx_train,y_train], np.c_[idx_test,y_test]\n",
    "    X, y = np.r_[X_train,X_test], np.r_[y_train,y_test]\n",
    "    X, y = X[np.argsort(X[:,0])], y[np.argsort(y[:,0])]\n",
    "    X, y = np.delete(X, 0, 1), np.delete(y, 0, 1)\n",
    "    \n",
    "    # tree predictions (only test observations will be retrieved later on)\n",
    "    preds_tree = extra.predict(X).reshape(-1,1)\n",
    "    \n",
    "    # Obtain train and test subsets created by the leaf node partitioning\n",
    "    # iterables are a list of Int64index objects for the data in each leaf node\n",
    "    for leaf_train, leaf_test in zip(list(groups_train.values()),list(groups_test.values())) :\n",
    "        \n",
    "        # subset the data\n",
    "        X_train_sub, y_train_sub = X[leaf_train], y[leaf_train]\n",
    "        X_test_sub, y_test_sub, y_tree = X[leaf_test] ,y[leaf_test], preds_tree[leaf_test]\n",
    "        \n",
    "        # original indexes of the observations appearing in this leaf\n",
    "        train_indexes = np.array(leaf_train).reshape(-1,1)\n",
    "        test_indexes = np.array(leaf_test).reshape(-1,1)\n",
    "        \n",
    "        # training subset including original observation indexes\n",
    "        sub_train = np.concatenate((train_indexes, X_train_sub, y_train_sub), axis=1)\n",
    "        # testing subset including original observation indexes and tree predictions\n",
    "        sub_test = np.concatenate((test_indexes, X_test_sub, y_test_sub, y_tree), axis=1)\n",
    "\n",
    "        subsets.append([sub_train,sub_test])\n",
    "    \n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedded SVM Regressor\n",
    "for each subset an svm classifier is trained on the training subset and used to predict the corresponding leaf test test.\n",
    "\n",
    "Since support vector machines are not scale-invariant, the data are scaled to have zero mean and unit variance for each local SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svr_linear(subset):\n",
    "    \n",
    "    idx_train, X_train, y_train = subset[0][:,0], subset[0][:,1:-1], subset[0][:,-1]\n",
    "    idx_test,X_test,y_test = subset[1][:,0],subset[1][:,1:-1],subset[1][:,-1]\n",
    "        \n",
    "    # decide whether to solve in primal or dual\n",
    "    QP_bool = False if (X_train.shape[0] > X_train.shape[0]) else True\n",
    "        \n",
    "    # fit svm to subset\n",
    "    reg = svm.LinearSVR(dual=QP_bool)\n",
    "    reg.fit(X_train,y_train)\n",
    "        \n",
    "    # obtain predictions for subset\n",
    "    svm_pred = reg.predict(X_test)\n",
    "    svm_pred = np.concatenate((idx_test.reshape(-1,1), svm_pred.reshape(-1,1)), axis=1)\n",
    "        \n",
    "    return svm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svr_sgd(subset):\n",
    "    \n",
    "    idx_train, X_train, y_train = subset[0][:,0], subset[0][:,1:-1], subset[0][:,-1]\n",
    "    idx_test,X_test,y_test = subset[1][:,0],subset[1][:,1:-1],subset[1][:,-1]\n",
    "                \n",
    "    # fit svm to subset\n",
    "    reg = linear_model.SGDRegressor(early_stopping=True)\n",
    "    reg.fit(X_train,y_train)\n",
    "        \n",
    "    # obtain predictions for subset\n",
    "    svm_pred = reg.predict(X_test)\n",
    "    svm_pred = np.concatenate((idx_test.reshape(-1,1), svm_pred.reshape(-1,1)), axis=1)\n",
    "        \n",
    "    return svm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svr_kernel(subset):\n",
    "    \n",
    "    idx_train, X_train, y_train = subset[0][:,0], subset[0][:,1:-1], subset[0][:,-1]\n",
    "    idx_test,X_test,y_test = subset[1][:,0],subset[1][:,1:-1],subset[1][:,-1]\n",
    "                \n",
    "    # fit svm to subset\n",
    "    reg = svm.SVR()\n",
    "    reg.fit(X_train,y_train)\n",
    "        \n",
    "    # obtain predictions for subset\n",
    "    svm_pred = reg.predict(X_test)\n",
    "    svm_pred = np.concatenate((idx_test.reshape(-1,1), svm_pred.reshape(-1,1)), axis=1)\n",
    "        \n",
    "    return svm_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concurrent SVM execution across leaf nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_tree_linear(X_train,X_test, y_train,y_test, idx_train,idx_test):\n",
    "    \n",
    "    # Obtain subsets\n",
    "    subsets = get_groups(X_train,X_test, y_train,y_test, idx_train,idx_test)\n",
    "    \n",
    "    preds_leaf = []\n",
    "    \n",
    "    # Run SVM's in parallel\n",
    "    with Parallel() as parallel:\n",
    "        result = parallel(delayed(fit_svr_linear)(subset) for subset in subsets)\n",
    "        preds_leaf.append(result)\n",
    "        \n",
    "    # aggregate predictions of the leafs into one set of predictions for the tree\n",
    "    preds_all = np.concatenate(preds_leaf[0],axis=0)\n",
    "    \n",
    "    # sort predictions by their index\n",
    "    preds_sorted = preds_all[np.argsort(preds_all[:,0])]\n",
    "    \n",
    "    return preds_sorted[:,1].reshape(-1,1) # return predictions without index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_tree_sgd(X_train,X_test, y_train,y_test, idx_train,idx_test):\n",
    "    \n",
    "    # Obtain subsets\n",
    "    subsets = tree_partition(X_train,X_test, y_train,y_test, idx_train,idx_test)\n",
    "    \n",
    "    preds_leaf = []\n",
    "    \n",
    "    # Run SVM's in parallel\n",
    "    with Parallel() as parallel:\n",
    "        result = parallel(delayed(fit_svr_sgd)(subset) for subset in subsets)\n",
    "        preds_leaf.append(result)\n",
    "        \n",
    "    # aggregate predictions of the leafs into one set of predictions for the tree\n",
    "    preds_all = np.concatenate(preds_leaf[0],axis=0)\n",
    "    \n",
    "    # sort predictions by their index\n",
    "    preds_sorted = preds_all[np.argsort(preds_all[:,0])]\n",
    "    \n",
    "    return preds_sorted[:,1].reshape(-1,1) # return predictions without index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_tree_kernel(X,y, X_train,X_test, y_train,y_test, idx_train,idx_test):\n",
    "    \n",
    "    # Obtain subsets\n",
    "    subsets = tree_partition(X_train,X_test, y_train,y_test, idx_train,idx_test)\n",
    "    \n",
    "    preds_leaf = []\n",
    "    \n",
    "    # Run SVM's in parallel\n",
    "    with Parallel() as parallel:\n",
    "        result = parallel(delayed(fit_svr_kernel)(subset) for subset in subsets)\n",
    "        preds_leaf.append(result)\n",
    "        \n",
    "    # aggregate predictions of the leafs into one set of predictions for the tree\n",
    "    preds_all = np.concatenate(preds_leaf[0],axis=0)\n",
    "    \n",
    "    # sort predictions by their index\n",
    "    preds_sorted = preds_all[np.argsort(preds_all[:,0])]\n",
    "    \n",
    "    return preds_sorted[:,1].reshape(-1,1) # return predictions without index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the above procedure for multiple trees in parallel\n",
    "This results in a support vector machine embedded random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run trees in parallel using all cores\n",
    "def rf_svr(X,y):\n",
    "    \n",
    "    # amount of trees in forest\n",
    "    trees = 100\n",
    "    \n",
    "    forest_pred=[]\n",
    "    \n",
    "    X_train,X_test, y_train,y_test, idx_train,idx_test = train_test_split(X,y\n",
    "                                                                          ,np.arange(len(X))\n",
    "                                                                          ,test_size=1/3)\n",
    "    t = time.time()\n",
    "    \n",
    "    with Parallel() as parallel:\n",
    "        forest_pred = parallel(delayed(svm_parallel)(X,y \n",
    "                                                     ,X_train,X_test \n",
    "                                                     ,y_train,y_test\n",
    "                                                     ,idx_train,idx_test) for i in range(1,trees))\n",
    "    \n",
    "    # training time\n",
    "    training_time = time.time() - t\n",
    "    \n",
    "    # reshape array such that column k denotes prediction for tree k\n",
    "    forest_pred = np.concatenate(forest_pred,axis=1)\n",
    "    \n",
    "    mean_pred = np.apply_along_axis(np.mean, 1, forest_pred) \n",
    "    \n",
    "    test = y_test[np.argsort(idx_test)]\n",
    "    \n",
    "    R_2 = metrics.r2_score(test, mean_pred)\n",
    "    \n",
    "    return R_2, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
